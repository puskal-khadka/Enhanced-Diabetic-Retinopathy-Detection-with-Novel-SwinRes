{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-23T05:14:46.264029Z","iopub.status.busy":"2024-09-23T05:14:46.263139Z","iopub.status.idle":"2024-09-23T05:14:46.270404Z","shell.execute_reply":"2024-09-23T05:14:46.269390Z","shell.execute_reply.started":"2024-09-23T05:14:46.263987Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","import torch.utils.data.dataloader\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","import numpy as np\n","from tqdm import tqdm\n","from torchvision.models.swin_transformer import swin_t\n","from torchvision.models import resnet50, ResNet50_Weights\n","import cv2 as cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T05:16:46.646301Z","iopub.status.busy":"2024-09-23T05:16:46.645533Z","iopub.status.idle":"2024-09-23T05:16:49.059664Z","shell.execute_reply":"2024-09-23T05:16:49.058540Z","shell.execute_reply.started":"2024-09-23T05:16:46.646257Z"},"trusted":true},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.Resize((256,256)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","])\n","\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","df = pd.read_csv('./dataset/raw/aptos-eye/train.csv')\n","\n","train_df, val_df = train_test_split(df,test_size=0.1,random_state=8)\n","\n","print(train_df['diagnosis'].value_counts())\n","print(val_df['diagnosis'].value_counts())\n","\n","    \n","\n","class CustomDataset(Dataset):\n","    def __init__(self, df, img_dir_path, extension =\".png\", transform=None):\n","        self.df = df\n","        self.img_dir_path = img_dir_path\n","        self.extension = extension\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        frame = self.df.iloc[index]\n","        img_name = frame['id_code']\n","        label = frame['diagnosis']\n","        img_path = f\"{self.img_dir_path}/{img_name}{self.extension}\"\n","\n","        img = cv2.imread(img_path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = cv2.resize(img, (256, 256))      \n","        image = Image.fromarray(img) \n","\n","        if self.transform is not None:\n","            image = self.transform(image)\n","\n","        return image, label \n","    \n","\n","batch_size = 40\n","\n","train_dataset = CustomDataset(df = train_df, img_dir_path=\"./dataset/raw/aptos-eye/train_images\", transform=transform)\n","val_dataset = CustomDataset(df = val_df, img_dir_path=\"./dataset/raw/aptos-eye/train_images\", transform=transform)\n","\n","train_dataloader = DataLoader (dataset= train_dataset, batch_size=batch_size, shuffle = True)\n","val_dataloader = DataLoader (dataset= val_dataset, batch_size=batch_size, shuffle = True)\n","\n","\n","\n","def visualizeImage( count=5):\n","    plt.figure(figsize=(16,9))\n","    for i in range(count):\n","        plt.subplot(1,count, i+1 )\n","        img,label = train_dataset[i]\n","        plt.title(label)\n","        plt.imshow(img.permute(1,2,0))\n","\n","\n","visualizeImage()    \n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T05:17:07.565297Z","iopub.status.busy":"2024-09-23T05:17:07.564534Z","iopub.status.idle":"2024-09-23T05:17:07.573405Z","shell.execute_reply":"2024-09-23T05:17:07.572433Z","shell.execute_reply.started":"2024-09-23T05:17:07.565253Z"},"trusted":true},"outputs":[],"source":["class SwinResModel(nn.Module):\n","    def __init__(self, out_features=5):\n","        super().__init__()\n","        self.swinModel = swin_t(weights=None)\n","    \n","        swin_in_features = self.swinModel.head.in_features\n","        self.swinModel.head = nn.Linear(swin_in_features, 150)\n","                                   \n","        self.resModel = resnet50(weights=None)\n","     \n","        res_in_features = self.resModel.fc.in_features\n","        self.resModel.fc = nn.Linear(res_in_features, 150)     \n","\n","        self.fc = nn.Sequential(\n","            nn.BatchNorm1d(300),\n","            nn.ReLU(),\n","            nn.Dropout(0.4),\n","            nn.Linear(300, 5)\n","        )     \n","        \n","\n","    def forward(self, x):\n","        out_swin = self.swinModel(x)\n","        out_res = self.resModel(x)\n","        cat = torch.cat((out_swin, out_res), 1)\n","        out = self.fc(cat)\n","        return out\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T05:17:25.063074Z","iopub.status.busy":"2024-09-23T05:17:25.062542Z","iopub.status.idle":"2024-09-23T05:17:25.070465Z","shell.execute_reply":"2024-09-23T05:17:25.069446Z","shell.execute_reply.started":"2024-09-23T05:17:25.063022Z"},"trusted":true},"outputs":[],"source":["\n","def visualizeResult(train_loss, train_acc, val_loss, val_acc, epochs):\n","    plt.title(\"Model's Loss Visualization\")\n","    plt.plot(range(epochs), train_loss, label = \"training loss\")\n","    plt.plot(range(epochs), val_loss, label = \"validation loss\")\n","    plt.legend()\n","    plt.xlabel (\"Epochs\")\n","    plt.ylabel(\"Loss\")\n","    plt.show()\n","\n","    plt.title(\"Model's Accuracy Visualization\")\n","    plt.plot(range(epochs), train_acc, label=\"training accuracy\")\n","    plt.plot(range(epochs), val_acc, label =\"validation accuracy\")\n","    plt.legend()\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T05:17:27.959656Z","iopub.status.busy":"2024-09-23T05:17:27.958897Z"},"trusted":true},"outputs":[],"source":["epochs = 30\n","\n","def training(\n","        model, criterion, optimizer, epochs\n","):\n","    train_loss = []\n","    train_acc = []\n","    val_loss = []\n","    val_acc = []\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        t_loss = 0\n","        t_acc = 0\n","        for i, data in enumerate(tqdm(train_dataloader)):\n","            imgs, labels = data\n","            imgs = imgs.to(device)\n","            labels = labels.to(device)\n","            optimizer.zero_grad()\n","            y_hat = model(imgs)\n","            loss = criterion(y_hat, labels)\n","            loss.backward()\n","            optimizer.step()\n","            \n","            t_loss+=loss.item()\n","            prediction_indices = torch.argmax(y_hat,1)\n","            correct = 0\n","            correct += (prediction_indices == labels).sum().item()\n","            t_acc += correct/labels.size(0)\n","\n","        train_loss.append(t_loss/len(train_dataloader))\n","        train_acc.append(t_acc/len(train_dataloader))\n","\n","\n","        model.eval()\n","        v_loss = 0\n","        v_acc = 0\n","        with torch.no_grad():\n","            for i, data in enumerate(val_dataloader):\n","                imgs, labels = data\n","                imgs = imgs.to(device)\n","                labels = labels.to(device)\n","                y_hat = model(imgs)\n","                loss = criterion(y_hat, labels)\n","                v_loss+=loss.item()\n","\n","                prediction_indices = torch.argmax(y_hat, 1)\n","                correct = 0\n","                correct += (prediction_indices==labels).sum().item()\n","                v_acc += correct/labels.size(0)\n","               \n","    \n","        val_loss.append(v_loss/len(val_dataloader))\n","        val_acc.append(v_acc/len(val_dataloader)) \n","\n","        print(f'Epoch {epoch+1}  Train Loss: {train_loss[epoch]:.2f},  Train accuracy: {train_acc[epoch]:.2f}, Validation Loss: {val_loss[epoch]:.2f},  Validation accuracy: {val_acc[epoch]:.2f}')\n","    \n","    torch.save(model.state_dict(), '/kaggle/working/resswin.pt')\n","    visualizeResult(train_loss, train_acc, val_loss, val_acc, epochs)\n","    \n","\n","\n","model = SwinResModel().to(device)\n","criterion = nn.CrossEntropyLoss()\n","learning_rate = 0.001\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr= learning_rate)\n","\n","\n","training(model, criterion, optimizer, epochs)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#inference\n","\n","eyeClass = {0:'Normal', 1: 'Mild', 2:'Moderate',  \n","             3:'Severe', 4:'Proliferative'}\n","\n","\n","def inference(\n","        model: torch.nn.Module,\n","        device: torch.device,\n","        image:Image,\n","):\n","    model = model.to(device)\n","    model.eval() \n","    image = transform(image) \n","    with torch.no_grad():\n","        img = image.to(device).unsqueeze(0)\n","        prediction = model(img).squeeze(0)\n","        print(prediction)\n","        predict_index = torch.argmax(prediction,0).item()\n","        eye_diagnosis = eyeClass[predict_index]\n","        print(f'prediction: {eye_diagnosis}')\n","\n","\n","test_df = pd.read_csv(\"./dataset/raw/aptos-eye/sample_submission.csv\")\n","n = np.random.randint(test_df.shape[0])\n","row = test_df.iloc[n]\n","row_img = row[\"id_code\"]\n","print(f\"img: {row_img}  label: {eyeClass[row['diagnosis']]}\")\n","patient_eye_image = Image.open(f\"./dataset/raw/aptos-eye/test_images/{row_img}.png\")\n","\n","\n","inference(model, device, patient_eye_image)\n","\n","        \n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":875431,"sourceId":14774,"sourceType":"competition"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":4}
