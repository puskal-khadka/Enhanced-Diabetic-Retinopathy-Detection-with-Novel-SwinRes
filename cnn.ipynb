{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-23T05:14:46.264029Z","iopub.status.busy":"2024-09-23T05:14:46.263139Z","iopub.status.idle":"2024-09-23T05:14:46.270404Z","shell.execute_reply":"2024-09-23T05:14:46.269390Z","shell.execute_reply.started":"2024-09-23T05:14:46.263987Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","import torch.utils.data.dataloader\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","import numpy as np\n","from tqdm import tqdm\n","import cv2 as cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T05:16:46.646301Z","iopub.status.busy":"2024-09-23T05:16:46.645533Z","iopub.status.idle":"2024-09-23T05:16:49.059664Z","shell.execute_reply":"2024-09-23T05:16:49.058540Z","shell.execute_reply.started":"2024-09-23T05:16:46.646257Z"},"trusted":true},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.Resize((256,256)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","])\n","\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_df = pd.read_csv('./dataset/raw/aptos-eye/train.csv')\n","\n","train_df, val_df = train_test_split(train_df,test_size=0.15,random_state=42)\n","\n","print(train_df['diagnosis'].value_counts())\n","print(val_df['diagnosis'].value_counts())\n","\n","def circle_crop(img):\n","    img = crop_image_from_gray(img)\n","    height, width, depth = img.shape\n","    largest_side = np.max((height, width))\n","    img = cv2.resize(img, (largest_side, largest_side))\n","    height, width, depth = img.shape\n","    x = int(width / 2)\n","    y = int(height / 2)\n","    r = np.amin((x, y))\n","    circle_img = np.zeros((height, width), np.uint8)\n","    cv2.circle(circle_img, (x, y), int(r), 1, thickness=-1)\n","    img = cv2.bitwise_and(img, img, mask=circle_img)\n","    img = crop_image_from_gray(img)\n","\n","    return img\n","\n","def crop_image_from_gray(img,tol=7):\n","    if img.ndim ==2:\n","        mask = img>tol\n","        return img[np.ix_(mask.any(1),mask.any(0))]\n","    elif img.ndim==3:\n","        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","        mask = gray_img>tol\n","        \n","        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n","        if (check_shape == 0):\n","            return img \n","        else:\n","            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n","            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n","            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n","            img = np.stack([img1,img2,img3],axis=-1)\n","        return img\n","    \n","\n","class CustomDataset(Dataset):\n","    def __init__(self, df, img_dir_path, extension =\".png\", transform=None):\n","        self.df = df\n","        self.img_dir_path = img_dir_path\n","        self.extension = extension\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        frame = self.df.iloc[index]\n","        img_name = frame['id_code']\n","        label = frame['diagnosis']\n","        img_path = f\"{self.img_dir_path}/{img_name}{self.extension}\"\n","\n","        img = cv2.imread(img_path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = cv2.resize(img, (256, 256))\n","        img = circle_crop(img)\n","        img = cv2.addWeighted ( img,4, cv2.GaussianBlur( img , (0,0) , 10) ,-4 ,128)       \n","        image = Image.fromarray(img) \n","\n","        if self.transform is not None:\n","            image = self.transform(image)\n","\n","        return image, label \n","    \n","\n","batch_size = 40\n","\n","train_dataset = CustomDataset(df = train_df, img_dir_path=\"./dataset/raw/aptos-eye/train_images\", transform=transform)\n","val_dataset = CustomDataset(df = val_df, img_dir_path=\"./dataset/raw/aptos-eye/train_images\", transform=transform)\n","\n","train_dataloader = DataLoader (dataset= train_dataset, batch_size=batch_size, shuffle = True)\n","val_dataloader = DataLoader (dataset= val_dataset, batch_size=batch_size, shuffle = True)\n","\n","\n","def visualizeImage( count=5):\n","    plt.figure(figsize=(16,9))\n","    for i in range(count):\n","        plt.subplot(1,count, i+1 )\n","        img,label = train_dataset[i]\n","        plt.title(label)\n","        plt.imshow(img.permute(1,2,0))\n","\n","\n","visualizeImage()    \n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T05:17:07.565297Z","iopub.status.busy":"2024-09-23T05:17:07.564534Z","iopub.status.idle":"2024-09-23T05:17:07.573405Z","shell.execute_reply":"2024-09-23T05:17:07.572433Z","shell.execute_reply.started":"2024-09-23T05:17:07.565253Z"},"trusted":true},"outputs":[],"source":["class CnnModel(nn.Module):\n","    def __init__(self):\n","        super(CnnModel, self).__init__()\n","\n","        self.cnn_model = nn.Sequential(\n","            nn.Conv2d(in_channels=3,out_channels=6, kernel_size=5),\n","            nn.ReLU(),\n","            nn.AvgPool2d(kernel_size=2,stride=5),\n","            nn.Conv2d(in_channels=6,out_channels=16, kernel_size=5),\n","            nn.ReLU(),\n","            nn.AvgPool2d(kernel_size=2,stride=5),\n","        )\n","\n","        self.fc_model = nn.Sequential(\n","            nn.Linear(in_features= 1600, out_features=120),\n","            nn.ReLU(),\n","            nn.Linear(in_features= 120, out_features= 84 ),\n","            nn.ReLU(),\n","            nn.Linear(in_features= 84, out_features= 5 ),\n","        )\n","\n","\n","    def forward(self, x):\n","        x = self.cnn_model(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc_model(x)\n","        x = F.sigmoid(x)   \n","        return x"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T05:17:25.063074Z","iopub.status.busy":"2024-09-23T05:17:25.062542Z","iopub.status.idle":"2024-09-23T05:17:25.070465Z","shell.execute_reply":"2024-09-23T05:17:25.069446Z","shell.execute_reply.started":"2024-09-23T05:17:25.063022Z"},"trusted":true},"outputs":[],"source":["\n","def visualizeResult(train_loss, train_acc, val_loss, val_acc, epochs):\n","    plt.title(\"Model's Loss Visualization\")\n","    plt.plot(range(epochs), train_loss, label = \"training loss\")\n","    plt.plot(range(epochs), val_loss, label = \"validation loss\")\n","    plt.legend()\n","    plt.xlabel (\"Epochs\")\n","    plt.ylabel(\"Loss\")\n","    plt.show()\n","\n","    plt.title(\"Model's Accuracy Visualization\")\n","    plt.plot(range(epochs), train_acc, label=\"training accuracy\")\n","    plt.plot(range(epochs), val_acc, label =\"validation accuracy\")\n","    plt.legend()\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-23T05:17:27.959656Z","iopub.status.busy":"2024-09-23T05:17:27.958897Z"},"trusted":true},"outputs":[],"source":["epochs = 35\n","\n","def training(\n","        model, criterion, optimizer, epochs\n","):\n","    train_loss = []\n","    train_acc = []\n","    val_loss = []\n","    val_acc = []\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        t_loss = 0\n","        t_acc = 0\n","        for i, data in enumerate(tqdm(train_dataloader)):\n","            imgs, labels = data\n","            imgs = imgs.to(device)\n","            labels = labels.to(device)\n","            optimizer.zero_grad()\n","            y_hat = model(imgs)\n","            loss = criterion(y_hat, labels)\n","            loss.backward()\n","            optimizer.step()\n","            \n","            t_loss+=loss.item()\n","            prediction_indices = torch.argmax(y_hat,1)\n","            correct = 0\n","            correct += (prediction_indices == labels).sum().item()\n","            t_acc += correct/labels.size(0)\n","\n","        train_loss.append(t_loss/len(train_dataloader))\n","        train_acc.append(t_acc/len(train_dataloader))\n","\n","\n","        model.eval()\n","        v_loss = 0\n","        v_acc = 0\n","        with torch.no_grad():\n","            for i, data in enumerate(val_dataloader):\n","                imgs, labels = data\n","                imgs = imgs.to(device)\n","                labels = labels.to(device)\n","                y_hat = model(imgs)\n","                loss = criterion(y_hat, labels)\n","                v_loss+=loss.item()\n","\n","                prediction_indices = torch.argmax(y_hat, 1)\n","                correct = 0\n","                correct += (prediction_indices==labels).sum().item()\n","                v_acc += correct/labels.size(0)\n","               \n","    \n","        val_loss.append(v_loss/len(val_dataloader))\n","        val_acc.append(v_acc/len(val_dataloader)) \n","\n","        print(f'Epoch {epoch+1}  Train Loss: {train_loss[epoch]:.2f},  Train accuracy: {train_acc[epoch]:.2f}, Validation Loss: {val_loss[epoch]:.2f},  Validation accuracy: {val_acc[epoch]:.2f}')\n","    \n","    torch.save(model.state_dict(), 'swint.pt')\n","    visualizeResult(train_loss, train_acc, val_loss, val_acc, epochs)\n","    \n","\n","\n","model = CnnModel().to(device)\n","criterion = nn.CrossEntropyLoss()\n","learning_rate = 0.001\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr= learning_rate)\n","\n","\n","training(model, criterion, optimizer, epochs)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["eyeClass = {0:'Normal', 1: 'Mild', 2:'Moderate',  \n","             3:'Severe', 4:'Proliferative'}\n","\n","def inference(\n","        model: torch.nn.Module,\n","        device: torch.device,\n","        image:Image,\n","):\n","    model = model.to(device)\n","    model.eval() \n","    image = transform(image) \n","    with torch.no_grad():\n","        img = image.to(device).unsqueeze(0)\n","        prediction = model(img).squeeze(0)\n","        print(prediction)\n","        predict_index = torch.argmax(prediction,0).item()\n","        eye_diagnosis = eyeClass[predict_index]\n","        print(f'prediction: {eye_diagnosis}')\n","\n","\n","test_df = pd.read_csv(\"./dataset/raw/aptos-eye/sample_submission.csv\")\n","n = np.random.randint(test_df.shape[0])\n","row = test_df.iloc[n]\n","row_img = row[\"id_code\"]\n","print(f\"img: {row_img}  label: {eyeClass[row['diagnosis']]}\")\n","patient_eye_image = Image.open(f\"./dataset/raw/aptos-eye/test_images/{row_img}.png\")\n","\n","\n","inference(model, device, patient_eye_image)\n","\n","        \n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":875431,"sourceId":14774,"sourceType":"competition"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":4}
